import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import jieba
from collections import Counter
import re

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="ç«å“è¯„è®ºæ·±åº¦åˆ†æçœ‹æ¿", layout="wide")

st.title("ğŸ›ï¸ ç«å“è¯„è®ºæ·±åº¦åˆ†æçœ‹æ¿")
st.markdown("ä¸Šä¼ å–å®¶ç²¾çµå¯¼å‡ºçš„è¯„è®ºè¡¨æ ¼ï¼Œè‡ªåŠ¨åˆ†ææ¶ˆè´¹è€…ç”»åƒä¸ç—›ç‚¹ã€‚")

# --- æ ¸å¿ƒå¤„ç†å‡½æ•° ---

def clean_text(text):
    if pd.isna(text):
        return ""
    # å»é™¤ç‰¹æ®Šç¬¦å·ï¼Œä¿ç•™ä¸­æ–‡å’Œè‹±æ–‡
    return re.sub(r'[^\w\s\u4e00-\u9fa5]', '', str(text))

def get_keywords(text_series, top_n=20):
    text_combined = " ".join(text_series.dropna().astype(str).tolist())
    # è¿™é‡Œå¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰è¯å…¸ä¼˜åŒ–ï¼Œè¿™é‡Œä½¿ç”¨åŸºç¡€åˆ†è¯
    words = jieba.lcut(text_combined)
    # åœç”¨è¯è¿‡æ»¤ï¼ˆç¤ºä¾‹ï¼Œå®é™…éœ€æ›´å®Œå–„çš„åœç”¨è¯è¡¨ï¼‰
    stopwords = ['çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'åœ¨', 'å’Œ', 'ä¹Ÿ', 'éƒ½', 'å°±', 'ç”¨', 'æœ‰', 'å¾ˆ', 'ä¹°', 'the', 'and', 'to', 'a', 'of', 'it', 'is', 'in']
    filtered_words = [w for w in words if len(w) > 1 and w.lower() not in stopwords]
    return Counter(filtered_words).most_common(top_n)

def analyze_sentiment_group(df, rating_col, content_col):
    # ç®€å•çš„åŸºäºè¯„åˆ†çš„æƒ…æ„Ÿåˆ†ç»„
    df['Sentiment'] = df[rating_col].apply(lambda x: 'å·®è¯„ (ç—›ç‚¹)' if x <= 3 else 'å¥½è¯„ (å–ç‚¹)')
    return df

# --- ä¾§è¾¹æ ï¼šæ•°æ®ä¸Šä¼  ---
uploaded_file = st.sidebar.file_uploader("è¯·ä¸Šä¼ è¯„è®º Excel/CSV æ–‡ä»¶", type=['xlsx', 'csv'])

if uploaded_file:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…±åŒ…å« {len(df)} æ¡è¯„è®ºã€‚")
        
        # --- æ•°æ®åˆ—æ˜ å°„ï¼ˆæ ¹æ®å–å®¶ç²¾çµå¯¼å‡ºæ ¼å¼è°ƒæ•´ï¼‰ ---
        # å‡è®¾å¸¸è§åˆ—åï¼Œå¦‚æœæŠ¥é”™ï¼Œç”¨æˆ·å¯åœ¨ç•Œé¢é€‰æ‹©
        columns = df.columns.tolist()
        st.sidebar.markdown("### ğŸ”§ æ•°æ®åˆ—æ˜ å°„")
        rating_col = st.sidebar.selectbox("é€‰æ‹©è¯„åˆ†åˆ—", columns, index=columns.index('rating') if 'rating' in columns else 0)
        content_col = st.sidebar.selectbox("é€‰æ‹©è¯„è®ºå†…å®¹åˆ—", columns, index=columns.index('content') if 'content' in columns else 0)
        date_col = st.sidebar.selectbox("é€‰æ‹©æ—¶é—´åˆ—", columns, index=columns.index('date') if 'date' in columns else 0)
        variant_col = st.sidebar.selectbox("é€‰æ‹©å˜ä½“/SKUåˆ— (å¯é€‰)", ['æ— '] + columns)

        # æ•°æ®é¢„å¤„ç†
        df = analyze_sentiment_group(df, rating_col, content_col)
        df['Cleaned_Content'] = df[content_col].apply(clean_text)

        # --- ç¬¬ä¸€éƒ¨åˆ†ï¼šå®è§‚æ¦‚è§ˆ (è¯„åˆ†ä¸è¶‹åŠ¿) ---
        st.header("1. å®è§‚æ•°æ®æ¦‚è§ˆ")
        c1, c2, c3 = st.columns(3)
        avg_rating = df[rating_col].mean()
        c1.metric("å¹³å‡è¯„åˆ†", f"{avg_rating:.2f} â­")
        c2.metric("è¯„è®ºæ€»æ•°", len(df))
        c3.metric("å·®è¯„å æ¯” (<=3æ˜Ÿ)", f"{(len(df[df[rating_col]<=3])/len(df)*100):.1f}%")

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("è¯„åˆ†ç­‰çº§åˆ†å¸ƒ")
            fig_rating = px.bar(df[rating_col].value_counts().sort_index(), title="æ˜Ÿçº§åˆ†å¸ƒå›¾", labels={'index':'æ˜Ÿçº§', 'value':'æ•°é‡'})
            st.plotly_chart(fig_rating, use_container_width=True)
        
        with col2:
            st.subheader("è¯„è®ºæ—¶é—´è¶‹åŠ¿")
            if date_col:
                try:
                    df[date_col] = pd.to_datetime(df[date_col])
                    time_trend = df.resample('M', on=date_col).size().reset_index(name='count')
                    fig_time = px.line(time_trend, x=date_col, y='count', title="æœˆåº¦è¯„è®ºè¶‹åŠ¿ (æ·¡æ—ºå­£åˆ¤æ–­)")
                    st.plotly_chart(fig_time, use_container_width=True)
                except:
                    st.warning("æ—¶é—´æ ¼å¼è§£æå¤±è´¥ï¼Œè·³è¿‡è¶‹åŠ¿åˆ†æ")

        st.markdown("---")

        # --- ç¬¬äºŒéƒ¨åˆ†ï¼šæ¶ˆè´¹è€…ç”»åƒä¸åœºæ™¯åˆ†æ ---
        st.header("2. æ¶ˆè´¹è€…ç”»åƒä¸ä½¿ç”¨åœºæ™¯ (åŸºäºé«˜é¢‘è¯)")
        
        # æå–å…¨é‡å…³é”®è¯
        all_keywords = get_keywords(df['Cleaned_Content'], top_n=50)
        
        c_1, c_2 = st.columns(2)
        with c_1:
            st.subheader("ğŸ” åœºæ™¯ä¸äººç¾¤ç‰¹å¾ (æ¨æµ‹)")
            st.markdown("""
            *æç¤ºï¼šæ­¤å¤„åŸºäºè¯é¢‘ç»Ÿè®¡ï¼Œè¯·ç»“åˆä¸Šä¸‹æ–‡è§£è¯»ã€‚*
            """)
            # è¿™é‡Œçš„é€»è¾‘æ˜¯å¯»æ‰¾ç‰¹å®šçš„åœºæ™¯è¯ï¼ˆéœ€äººå·¥è§‚å¯Ÿé«˜é¢‘è¯åˆ—è¡¨ï¼‰
            word_freq_df = pd.DataFrame(all_keywords, columns=['å…³é”®è¯', 'é¢‘ç‡'])
            fig_cloud = px.bar(word_freq_df.head(15), x='é¢‘ç‡', y='å…³é”®è¯', orientation='h', title="Top 15 æ ¸å¿ƒé«˜é¢‘è¯")
            fig_cloud.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig_cloud, use_container_width=True)

        with c_2:
            st.subheader("ğŸ’¡ è´­ä¹°åŠ¨æœºä¸å¥½è¯„ç‚¹ (4-5æ˜Ÿ)")
            pos_df = df[df[rating_col] >= 4]
            pos_keywords = get_keywords(pos_df['Cleaned_Content'], top_n=10)
            st.write("æ¶ˆè´¹è€…æœ€æ»¡æ„çš„ç‚¹ï¼ˆHigh Frequencyï¼‰ï¼š")
            for word, freq in pos_keywords:
                st.write(f"- **{word}**: å‡ºç° {freq} æ¬¡")

        st.markdown("---")

        # --- ç¬¬ä¸‰éƒ¨åˆ†ï¼šå·®è¯„ä¸ç—›ç‚¹æ·±åº¦æŒ–æ˜ ---
        st.header("3. âš ï¸ å·®è¯„ä¸æœªè¢«æ»¡è¶³çš„éœ€æ±‚ (ç—›ç‚¹åˆ†æ)")
        
        neg_df = df[df[rating_col] <= 3]
        
        if not neg_df.empty:
            col_neg1, col_neg2 = st.columns([1, 2])
            
            with col_neg1:
                st.subheader("ä¸»è¦å·®è¯„ç‚¹")
                neg_keywords = get_keywords(neg_df['Cleaned_Content'], top_n=15)
                st.table(pd.DataFrame(neg_keywords, columns=['è´Ÿé¢å…³é”®è¯', 'é¢‘ç‡']))
            
            with col_neg2:
                st.subheader("å·®è¯„åŸæ–‡æ‘˜è¦ (Top 5)")
                # ç®€å•çš„æŒ‰é•¿åº¦å±•ç¤ºå‡ æ¡å…¸å‹çš„é•¿å·®è¯„ï¼Œé€šå¸¸é•¿å·®è¯„åŒ…å«æ›´å¤šç»†èŠ‚
                neg_df['len'] = neg_df[content_col].astype(str).str.len()
                top_neg_reviews = neg_df.sort_values(by='len', ascending=False).head(5)
                
                for index, row in top_neg_reviews.iterrows():
                    st.error(f"â­ {row[rating_col]}æ˜Ÿ | {row[date_col] if date_col else ''}\n\n\"{row[content_col]}\"")
        else:
            st.success("è¯¥äº§å“æ²¡æœ‰æ˜æ˜¾çš„å·®è¯„ï¼ˆ3æ˜ŸåŠä»¥ä¸‹æ•°æ®ä¸ºç©ºï¼‰ã€‚")

        # --- ç¬¬å››éƒ¨åˆ†ï¼šå˜ä½“åˆ†æ (å¦‚æœæœ‰) ---
        if variant_col and variant_col != 'æ— ':
            st.header("4. å˜ä½“/è§„æ ¼åˆ†æ")
            st.markdown("æŸ¥çœ‹å“ªç§é¢œè‰²/å°ºå¯¸é—®é¢˜æœ€å¤š")
            variant_counts = df.groupby(variant_col)[rating_col].mean().sort_values()
            st.bar_chart(variant_counts)

    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æå‡ºé”™ï¼Œè¯·ç¡®ä¿ä¸Šä¼ äº†æ­£ç¡®çš„ CSV/Excel æ–‡ä»¶ã€‚é”™è¯¯ä¿¡æ¯: {e}")

else:
    st.info("ğŸ‘† è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶å¼€å§‹åˆ†æ")
